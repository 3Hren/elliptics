import sys
sys.path.append('/tmp/dnet/lib')
sys.path.append('/tmp/test/history.2')

from libelliptics_python import *

# groups used in metadata write
pohmelfs_groups = [1, 2, 3]
pohmelfs_log_file = '/tmp/test/history.2/python.log'

log = elliptics_log_file(pohmelfs_log_file, 10)
n = elliptics_node_python(log)
# we should only add own local group, since we do not want all updates to be repeated for all groups
n.add_groups([2])
n.add_remote('172.16.239.1', 1025)

__return_data = 'unused'

import struct
from sstable2 import sstable

import logging
FORMAT = "%(asctime)-15s %(process)d %(script)s %(dentry_name)s %(message)s"
logging.basicConfig(filename=pohmelfs_log_file, level=logging.DEBUG, format=FORMAT)

pohmelfs_offset = 0
pohmelfs_size = 0
# do not check csum
#pohmelfs_ioflags_read = 256
pohmelfs_ioflags_read = 0
pohmelfs_ioflags_write = 0
# do not lock operation, since we are 'inside' DNET_CMD_EXEC command already
pohmelfs_aflags = 16
pohmelfs_column = 0
pohmelfs_group_id = 0

def pohmelfs_write(parent_id, content):
	n.write_data(parent_id, content, pohmelfs_offset, pohmelfs_aflags, pohmelfs_ioflags_write)
	n.write_metadata(parent_id, '', pohmelfs_groups, pohmelfs_aflags)

def parse(buffer):
	# Header format:
	# 8 bytes: magic
	# 2 bytes: version
	# 2 bytes: chunk size
	# 4 bytes: number of chunks inside
	header_fmt = "<8sHHI"

	# Chunk header format:
	# 2 bytes: length in chunks
	# 2 bytes: current chunk
	# 2 bytes: key size
	# 2 bytes: payload size
	chunk_header_fmt = "<HHHH"
	chunk_header_size = 8

	# Parse header
	position = 0
	header = struct.unpack_from(header_fmt, buffer, position)
	position += struct.calcsize(header_fmt)

	header_chunk_size = header[2]
	header_count = header[3]
	header_strings_start = position

	keys = ''
	#print "chunk size:", header_chunk_size, ", chunks count:", header_count, ", strings start at", header_strings_start


	offset = header_strings_start
	while offset < header_strings_start + header_count * header_chunk_size:
		chunk_header = struct.unpack_from(chunk_header_fmt, buffer, offset)
		if chunk_header[1] > 0:
			offset -= chunk_header[1]*header_chunk_size

		chunk_header = struct.unpack_from(chunk_header_fmt, buffer, offset)

		key_len = chunk_header[2]
		payload_len = chunk_header[3]

		key = ""
		payload = ""
		rec_offset = 0

		for i in xrange(0, chunk_header[0]):
			key_size = 0

			# Get key from chunks
			if key_len > 0:
				key_size = header_chunk_size - chunk_header_size
				if key_len < key_size:
					key_size = key_len

				key_offset = offset + rec_offset + chunk_header_size
				key += buffer[key_offset:(key_offset + key_size)]
				key_len -= key_size

			# Get payload from chunks
			if key_len == 0 and payload_len > 0:
				payload_size = header_chunk_size - chunk_header_size - key_size
				if payload_len < payload_size:
					payload_size = payload_len

				payload_offset = offset + rec_offset + chunk_header_size + key_size
				payload += buffer[payload_offset:(payload_offset + payload_size)]
				payload_len -= payload_size

			rec_offset += header_chunk_size
		keys += key + ' '
		#print key, payload
		offset += chunk_header[0]*header_chunk_size
	
	return keys
