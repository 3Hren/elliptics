Practical elliptics network in a nutshell.

This library provides a way to create a distributed hash table storage
with the versioned updates.

To create the storage one has to implement an application which will
create the node with given ID, which will join the network, add
transformation functions which will be used to create ID from the data
objects, and start doing IO using existing exported API functions.

Example application in the archive contains all those operations and
exports them via command line options.

Let's see how to create a simple distributed storage with the redundant
writes with an additional copy.

0. Compiling the sources.

$ ./configure
$ make
$ make install

1. Creating the first node with zero ID (default), listening on the
127.0.0.1:1025 IPv4 address and having /tmp/root0 root directory.

$ example -a 127.0.0.1:1025:2 -d /tmp/root0

Where -a switch provides local listening address in the addr:port:family format
(family 2 means IPv4, 10 - IPv6), -d is used to specify root directory to store
objects. Example application uses TCP, but one can also use any other network
protocol which is exported via sockets, it is specified in the configuration
request and is returned in lookup replies.

2. Adding second node into the storage. It will have hex
ID 1234567890abcde0000000000000000000000000, listen on the 127.0.0.0:1234 IPv4
address and having /tmp/root1 root directory. It will join via the first node
with the 127.0.0.1:1025 IPv4 address.

$ example -i 1234567890abcde0000 -a 127.0.0.1:1234:2 -r 127.0.0.1:1025:2 -d /tmp/root1 -j

Additional options include -r switch, which is used to specify the node used to
join the network through or send commands to, and -j is used to specify that we
want this node to join the network, so that it can also store data from other
clients. -i switch specifies node's ID. Order of the options matters, for example
if ID is specified after the join option, system will try to join the network with
the default zero ID (and will fail, since we already have such a node created
previously).

Each node will store a data with IDs which are less or equal to its own ID, so
the second node in the example will store objects whose IDs match
(0x0, 0x1234567890abcde0000000000000000000000000] range. The first node will
store everything less than zero (having a ring addressing it means that the
first node will store anything that has ID higher than the last node's ID,
i.e. higher than 0x1234567890abcde0000000000000000000000000).

3. Writing the local file (/tmp/some_file) into the storage and creating
a redundant copy. We will use two transformation functions for that
(sha1 and md5 from the OpenSSL in the example, can be your own which implement
init-update-final sequence). We still have to create a node which will connect
to the network and thus has to have an ID, but it will not join the network,
i.e. it will not store other's data. Our ID will be
hex 2222222200000000000000000000000000000000 and node will bind to
127.0.0.1:1111 IPv4 address and request data via the node with 127.0.0.1:1025 IPv4
address. Address to send command to can be any known server address, requests will
be properly forwarded between the nodes, if you connected to the node which does
not contain or will not store your data.

$ example -i 22222222 -a 127.0.0.1:1111:2 -r 127.0.0.1:1025:2 -T sha1 -T md5 -W /tmp/some_file

-T switch is used to specify multiple transformation functions, which will be
used to create ID of the file and its content. Having multiple transformation
functions means that each update will be repeated with each transforamation,
so we will hash /tmp/some_file (and its content) and put it into the network
with the different IDs, which potentially means that object will be placed on
the different nodes (it depends on amount of nodes and their IDs, as described
above example ID ranges).
-W option specifies a local file to write into the network.

4. Reading a local file from the network. We will use the same transformation
functions as in writing, so if one of them failed, we could switch to the second
and receive the object from a potentially different node.

$ example -i 22222222 -a 127.0.0.1:1111:2 -r 127.0.0.1:1025:2 -T sha1 -T md5 -R /tmp/some_file

-R option specifies a local file we want to read from the network. Its name
will be transformed via provided function(s), object will be fetched from the
network and written locally into the provided file. Reading callbacks may be
invoked multiple times with a different data which should be placed at different
offsets, there is a special flag set when more data is expected, this flag will
be cleared when reading is completed. Actually it is a transaction completion flag,
which, if set, means transaction is not yet fully completed and there will be
another invocations of the completion callback.

As with writing this hashed name is used as a global object ID, thus if multiple
clients write into file with the same name (i.e. /tmp/some_file),
their content will be overwritten.
Library provides low level interfaces where ID is specified by the caller,
so if your application does not work with files, it can be private indexes or
anything you like. Those interfaces only work with the single object,
i.e. it will send/receive data to/from the single node in the network and
redundancy steps should be done by the caller.

Using those interfaces it is possible to spread the big file over multiple nodes,
to implement this, writer should split object into multiple chunks and assign them
different IDs (for example it can be extended filename like
/tmp/some_file[null byte]offset or content checksum), thus they will be sent
to the nodes corresponding for storing those IDs. Reader should implement
the same technique.

Thus the simplest solution for the multiple datacenter localtions or geographical
bundling and load balancing is to assign nodes in the same datacenter IDs with
the higher byte equal to the datacenter number and use different transformation
functions which will hash the content and set the highest ID byte to the datacenter number.
Thus reading from the specified datacenter can be achieved by using the appropriate
transformation function and if reading fails (when datacenter is disconnected) other
functions will start working and data will be fetched from the different locations.

Originally object is placed into the network according either to the ID user provided
(if low level interfaces are used) or its hashed name. Each write into that object
creates additional transactions which store content to be written. They have IDs
being equal to the data checksums (created by the provided transformation functions),
and thus are potentially stored on the different nodes. Each write updates local
history of the object, so it is possible to recreate file how it existed in the past.
One can also create object locally by fetching its updates from the different nodes
if main storing node is not accessible. It requires to know the history and having
the original transaction though, which are stored on the node which hosts the object
itself :)

There is an idea of providing not only file based backends for the nodes, but also
stackable solutions like with transformation functions, when server provides a callback
to store data, and will place it either as a file in some dir, or database update
or anything else.
